// src/stores/lexiconStore.ts (ì™„ì „ ìˆ˜ì •)
import { create } from "zustand";
import { persist, createJSONStorage } from "zustand/middleware";
import type {
  Lexeme,
  POS,
  LangTag,
} from "@/features/learn/types/patternCore.types";

type Source = "user" | "global" | "pack";

interface LexiconState {
  hydrated: boolean;
  words: (Lexeme & { source: Source })[];
  loadedPacks: string[];
  isInitialized: boolean;

  // ê¸°ë³¸ CRUD
  addWord: (
    w: Omit<Lexeme & { source?: Source }, "id" | "createdAt">
  ) => string;
  updateWord: (id: string, upd: Partial<Lexeme>) => void;
  removeWord: (id: string) => void;

  // ê²€ìƒ‰ ë° í•„í„°
  search: (q: string) => (Lexeme & { source: Source })[];
  findByPos: (
    pos: POS[],
    categories?: LangTag[]
  ) => (Lexeme & { source: Source })[];

  // ë°ì´í„°íŒ© ê´€ë¦¬ - seedIfEmpty ëŒ€ì²´
  ensureMinimumWords: (
    count: number,
    categories?: LangTag[]
  ) => { added: number; totalBefore: number; totalAfter: number };

  // âœ… ìƒˆë¡œìš´ ì´ˆê¸°í™” í•¨ìˆ˜ (seedIfEmpty ëŒ€ì²´)
  initializeWithBasicWords: () => void;
  ensureBasicWordsAvailable: () => void;

  // ìœ í‹¸ë¦¬í‹°
  exportUserWords: () => Lexeme[];
  getWordsByCategory: (
    categories: LangTag[]
  ) => (Lexeme & { source: Source })[];

  // âœ… upsertGlobalWords ì¶”ê°€ (loadPacks.ts í˜¸í™˜ì„±)
  upsertGlobalWords: (lexemes: Array<Omit<Lexeme, "id" | "createdAt">>) => void;
}

// âœ… ê¸°ë³¸ ë‹¨ì–´ ì„¸íŠ¸ (í•˜ë“œì½”ë”©)
const BASIC_WORDS: Array<Omit<Lexeme, "id" | "createdAt">> = [
  // ê¸°ë³¸ ë™ì‚¬
  { en: "go", ko: "ê°€ë‹¤", pos: "VERB", tags: ["daily", "directions"] },
  { en: "come", ko: "ì˜¤ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "have", ko: "ê°€ì§€ë‹¤/ë¨¹ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "get", ko: "ë°›ë‹¤/ì‚¬ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "make", ko: "ë§Œë“¤ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "want", ko: "ì›í•˜ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "need", ko: "í•„ìš”í•˜ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "like", ko: "ì¢‹ì•„í•˜ë‹¤", pos: "VERB", tags: ["daily"] },

  // ê¸°ë³¸ ì¥ì†Œ
  { en: "home", ko: "ì§‘", pos: "PLACE", tags: ["daily"] },
  { en: "school", ko: "í•™êµ", pos: "PLACE", tags: ["daily", "school"] },
  { en: "office", ko: "íšŒì‚¬", pos: "PLACE", tags: ["daily", "business"] },
  { en: "store", ko: "ê°€ê²Œ", pos: "PLACE", tags: ["daily"] },
  { en: "hospital", ko: "ë³‘ì›", pos: "PLACE", tags: ["daily"] },
  { en: "bus stop", ko: "ë²„ìŠ¤ ì •ë¥˜ì¥", pos: "PLACE", tags: ["directions"] },
  { en: "subway station", ko: "ì§€í•˜ì² ì—­", pos: "PLACE", tags: ["directions"] },
  { en: "cafe", ko: "ì¹´í˜", pos: "PLACE", tags: ["daily"] },

  // ê¸°ë³¸ ì‚¬ëŒ
  { en: "friend", ko: "ì¹œêµ¬", pos: "PERSON", tags: ["daily"] },
  { en: "family", ko: "ê°€ì¡±", pos: "PERSON", tags: ["daily"] },
  { en: "teacher", ko: "ì„ ìƒë‹˜", pos: "PERSON", tags: ["school"] },
  { en: "student", ko: "í•™ìƒ", pos: "PERSON", tags: ["school"] },

  // ê¸°ë³¸ ë¬¼ê±´
  { en: "food", ko: "ìŒì‹", pos: "ITEM", tags: ["daily"] },
  { en: "water", ko: "ë¬¼", pos: "ITEM", tags: ["daily"] },
  { en: "coffee", ko: "ì»¤í”¼", pos: "ITEM", tags: ["daily"] },
  { en: "book", ko: "ì±…", pos: "ITEM", tags: ["daily", "school"] },
  { en: "phone", ko: "íœ´ëŒ€í°", pos: "ITEM", tags: ["daily"] },
  { en: "bag", ko: "ê°€ë°©", pos: "ITEM", tags: ["daily"] },

  // ê¸°ë³¸ ì‹œê°„
  { en: "today", ko: "ì˜¤ëŠ˜", pos: "TIME", tags: ["daily"] },
  { en: "tomorrow", ko: "ë‚´ì¼", pos: "TIME", tags: ["daily"] },
  { en: "morning", ko: "ì•„ì¹¨", pos: "TIME", tags: ["daily"] },
  { en: "afternoon", ko: "ì˜¤í›„", pos: "TIME", tags: ["daily"] },
  { en: "evening", ko: "ì €ë…", pos: "TIME", tags: ["daily"] },
  { en: "weekend", ko: "ì£¼ë§", pos: "TIME", tags: ["daily"] },
];

export const useLexiconStore = create<LexiconState>()(
  persist(
    (set, get) => ({
      hydrated: false,
      words: [],
      loadedPacks: [],
      isInitialized: false,

      addWord: (w) => {
        const normalizedEn = w.en.toLowerCase().trim();
        const exists = get().words.find(
          (x) => x.pos === w.pos && x.en.toLowerCase().trim() === normalizedEn
        );

        if (exists) {
          console.log(`âš ï¸ ì¤‘ë³µ ë‹¨ì–´ ë¬´ì‹œ: "${w.en}" (${w.pos})`);
          return exists.id;
        }

        const id = `lex_${Date.now()}_${Math.random()
          .toString(36)
          .substr(2, 9)}`;
        const now = new Date().toISOString();

        const item: Lexeme & { source: Source } = {
          id,
          en: w.en.trim(),
          ko: w.ko.trim(),
          pos: w.pos,
          tags: w.tags ?? [],
          createdAt: now,
          source: w.source ?? "user",
        };

        set((s) => ({ words: [item, ...s.words] }));
        return id;
      },

      updateWord: (id, upd) =>
        set((s) => ({
          words: s.words.map((x) =>
            x.id === id
              ? { ...x, ...upd, updatedAt: new Date().toISOString() }
              : x
          ),
        })),

      removeWord: (id) =>
        set((s) => ({ words: s.words.filter((x) => x.id !== id) })),

      search: (q) => {
        const n = q.toLowerCase().trim();
        return get().words.filter(
          (w) => w.en.toLowerCase().includes(n) || w.ko.includes(q)
        );
      },

      findByPos: (pos, categories) => {
        let filtered = get().words.filter((w) => pos.includes(w.pos));

        if (categories?.length) {
          filtered = filtered.filter((w) =>
            w.tags.some((tag) => categories.includes(tag))
          );
        }

        return filtered;
      },

      // âœ… upsertGlobalWords êµ¬í˜„ (loadPacks.ts í˜¸í™˜ì„±)
      upsertGlobalWords: (lexemes) => {
        const state = get();
        const existingKeys = new Set(
          state.words.map((w) => `${w.en.toLowerCase()}_${w.pos}`)
        );

        const newWords: (Lexeme & { source: Source })[] = lexemes
          .filter(
            (lexeme) =>
              !existingKeys.has(`${lexeme.en.toLowerCase()}_${lexeme.pos}`)
          )
          .map((lexeme, index) => ({
            id: `pack_${Date.now()}_${index}`,
            en: lexeme.en,
            ko: lexeme.ko,
            pos: lexeme.pos,
            tags: lexeme.tags || [],
            createdAt: new Date().toISOString(),
            source: "pack" as Source,
          }));

        if (newWords.length > 0) {
          set((state) => ({
            words: [...state.words, ...newWords],
          }));
          console.log(`âœ… ${newWords.length}ê°œ ê¸€ë¡œë²Œ ë‹¨ì–´ ì¶”ê°€ë¨`);
        }
      },

      // âœ… seedIfEmpty ëŒ€ì²´: ê¸°ë³¸ ë‹¨ì–´ë¡œ ì´ˆê¸°í™”
      initializeWithBasicWords: () => {
        const state = get();
        if (state.isInitialized) return;

        console.log("ğŸ”„ ê¸°ë³¸ ë‹¨ì–´ë¡œ ì´ˆê¸°í™” ì¤‘...");

        const existingKeys = new Set(
          state.words.map((w) => `${w.en.toLowerCase()}_${w.pos}`)
        );

        const newWords = BASIC_WORDS.filter(
          (word) => !existingKeys.has(`${word.en.toLowerCase()}_${word.pos}`)
        ).map((word, index) => ({
          id: `basic_${Date.now()}_${index}`,
          en: word.en,
          ko: word.ko,
          pos: word.pos,
          tags: word.tags,
          createdAt: new Date().toISOString(),
          source: "global" as Source,
        }));

        if (newWords.length > 0) {
          set((state) => ({
            words: [...state.words, ...newWords],
            isInitialized: true,
          }));
          console.log(`âœ… ${newWords.length}ê°œ ê¸°ë³¸ ë‹¨ì–´ ì¶”ê°€ë¨`);
        } else {
          set((state) => ({ ...state, isInitialized: true }));
        }
      },

      // âœ… ê¸°ë³¸ ë‹¨ì–´ ë³´ì¥ (íŒ¨í„´ ìƒì„± ì „ í˜¸ì¶œìš©)
      ensureBasicWordsAvailable: () => {
        const state = get();
        const posCount = state.words.reduce((acc, w) => {
          acc[w.pos] = (acc[w.pos] || 0) + 1;
          return acc;
        }, {} as Record<POS, number>);

        // ìµœì†Œ í•„ìš” ë‹¨ì–´ ì²´í¬
        const minimums = {
          VERB: 3,
          PLACE: 3,
          PERSON: 2,
          ITEM: 3,
          TIME: 2,
        };

        let needsMore = false;
        for (const [pos, min] of Object.entries(minimums)) {
          if ((posCount[pos as POS] || 0) < min) {
            needsMore = true;
            break;
          }
        }

        if (needsMore) {
          console.log("ğŸ“ˆ ê¸°ë³¸ ë‹¨ì–´ ì¶”ê°€ í•„ìš”, ìë™ ì¶”ê°€ ì¤‘...");
          get().initializeWithBasicWords();
        }
      },

      // ìµœì†Œ ë‹¨ì–´ ìˆ˜ ë³´ì¥
      ensureMinimumWords: (count, categories) => {
        const current = categories
          ? get().getWordsByCategory(categories)
          : get().words;

        const totalBefore = current.length;

        if (totalBefore >= count) {
          return { added: 0, totalBefore, totalAfter: totalBefore };
        }

        // ë¨¼ì € ê¸°ë³¸ ë‹¨ì–´ë¡œ ì±„ìš°ê¸° ì‹œë„
        get().initializeWithBasicWords();

        const afterBasic = categories
          ? get().getWordsByCategory(categories).length
          : get().words.length;

        return {
          added: afterBasic - totalBefore,
          totalBefore,
          totalAfter: afterBasic,
        };
      },

      getWordsByCategory: (categories) => {
        return get().words.filter((w) =>
          w.tags.some((tag) => categories.includes(tag))
        );
      },

      exportUserWords: () => get().words.filter((w) => w.source === "user"),
    }),
    {
      name: "mypattern-lexicon",
      storage: createJSONStorage(() => localStorage),
      partialize: (s) => ({
        words: s.words.filter((w) => w.source === "user"), // ì‚¬ìš©ì ë‹¨ì–´ë§Œ ì €ì¥
        loadedPacks: s.loadedPacks,
        isInitialized: s.isInitialized,
      }),
      onRehydrateStorage: () => (state, err) => {
        if (!err && state) {
          console.log("[lexiconStore] í•˜ì´ë“œë ˆì´ì…˜ ì™„ë£Œ", {
            words: state.words?.length,
            loadedPacks: state.loadedPacks?.length,
            isInitialized: state.isInitialized,
          });

          // âœ… í•˜ì´ë“œë ˆì´ì…˜ í›„ ìë™ìœ¼ë¡œ ê¸°ë³¸ ë‹¨ì–´ ì´ˆê¸°í™”
          setTimeout(() => {
            if (!state.isInitialized) {
              (state as LexiconState).initializeWithBasicWords();
            }
          }, 100);
        }

        return { hydrated: true };
      },
    }
  )
);
