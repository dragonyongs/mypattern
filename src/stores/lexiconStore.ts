// src/stores/lexiconStore.ts (ì™„ì „ ê°œì„  + ê¸°ì¡´ ë¡œì§ ìœ ì§€ ë²„ì „)

import { create } from "zustand";
import { persist, createJSONStorage } from "zustand/middleware";
import type {
  Lexeme,
  POS,
  LangTag,
} from "@/features/learn/types/patternCore.types";

type Source = "user" | "global" | "pack";

interface LexiconState {
  hydrated: boolean;
  words: (Lexeme & { source: Source })[];
  loadedPacks: string[];
  isInitialized: boolean;
  userAddedCoreWords: Set<string>;
  isLoadingPacks: boolean; // âœ… ë¡œë”© ìƒíƒœ ì¶”ê°€

  // ê¸°ë³¸ CRUD
  addWord: (w: Omit<Lexeme & { source: Source }, "id" | "createdAt">) => string;
  updateWord: (id: string, upd: Partial<Lexeme>) => void;
  removeWord: (id: string) => void;

  // ê²€ìƒ‰ ë° í•„í„°
  search: (q: string) => (Lexeme & { source: Source })[];
  findByPos: (
    pos: POS[],
    categories?: LangTag[]
  ) => (Lexeme & { source: Source })[];

  // ë°ì´í„°íŒ© ê´€ë¦¬
  ensureMinimumWords: (
    count: number,
    categories?: LangTag[]
  ) => { added: number; totalBefore: number; totalAfter: number };

  // ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
  initializeWithBasicWords: () => void;
  ensureBasicWordsAvailable: () => void;
  seedIfEmpty: () => void;
  loadJSONPacks: () => Promise<void>; // âœ… ì¶”ê°€

  // ì½”ì–´ ë‹¨ì–´ ê´€ë¦¬
  addCoreWordToUser: (wordId: string) => void;
  removeCoreWordFromUser: (wordId: string) => void;

  // ìœ í‹¸ë¦¬í‹°
  exportUserWords: () => Lexeme[];
  getWordsByCategory: (
    categories: LangTag[]
  ) => (Lexeme & { source: Source })[];

  // upsertGlobalWords
  upsertGlobalWords: (lexemes: Array<Omit<Lexeme, "id" | "createdAt">>) => void;
}

// âœ… ê¸°ë³¸ ë‹¨ì–´ ì„¸íŠ¸ (í•˜ë“œì½”ë”©)
const BASIC_WORDS: Array<Omit<Lexeme, "id" | "createdAt">> = [
  // ê¸°ë³¸ ë™ì‚¬
  { en: "go", ko: "ê°€ë‹¤", pos: "VERB", tags: ["daily", "directions"] },
  { en: "come", ko: "ì˜¤ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "have", ko: "ê°€ì§€ë‹¤/ë¨¹ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "get", ko: "ë°›ë‹¤/ì‚¬ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "make", ko: "ë§Œë“¤ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "want", ko: "ì›í•˜ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "need", ko: "í•„ìš”í•˜ë‹¤", pos: "VERB", tags: ["daily"] },
  { en: "like", ko: "ì¢‹ì•„í•˜ë‹¤", pos: "VERB", tags: ["daily"] },

  // ê¸°ë³¸ ì¥ì†Œ
  { en: "home", ko: "ì§‘", pos: "PLACE", tags: ["daily"] },
  { en: "school", ko: "í•™êµ", pos: "PLACE", tags: ["daily", "school"] },
  { en: "office", ko: "íšŒì‚¬", pos: "PLACE", tags: ["daily", "business"] },
  { en: "store", ko: "ê°€ê²Œ", pos: "PLACE", tags: ["daily"] },
  { en: "hospital", ko: "ë³‘ì›", pos: "PLACE", tags: ["daily"] },
  { en: "bus stop", ko: "ë²„ìŠ¤ ì •ë¥˜ì¥", pos: "PLACE", tags: ["directions"] },
  { en: "subway station", ko: "ì§€í•˜ì² ì—­", pos: "PLACE", tags: ["directions"] },
  { en: "cafe", ko: "ì¹´í˜", pos: "PLACE", tags: ["daily"] },

  // ê¸°ë³¸ ì‚¬ëŒ
  { en: "friend", ko: "ì¹œêµ¬", pos: "PERSON", tags: ["daily"] },
  { en: "family", ko: "ê°€ì¡±", pos: "PERSON", tags: ["daily"] },
  { en: "teacher", ko: "ì„ ìƒë‹˜", pos: "PERSON", tags: ["school"] },
  { en: "student", ko: "í•™ìƒ", pos: "PERSON", tags: ["school"] },

  // ê¸°ë³¸ ë¬¼ê±´
  { en: "food", ko: "ìŒì‹", pos: "ITEM", tags: ["daily"] },
  { en: "water", ko: "ë¬¼", pos: "ITEM", tags: ["daily"] },
  { en: "coffee", ko: "ì»¤í”¼", pos: "ITEM", tags: ["daily"] },
  { en: "book", ko: "ì±…", pos: "ITEM", tags: ["daily", "school"] },
  { en: "phone", ko: "íœ´ëŒ€í°", pos: "ITEM", tags: ["daily"] },
  { en: "bag", ko: "ê°€ë°©", pos: "ITEM", tags: ["daily"] },

  // ê¸°ë³¸ ì‹œê°„
  { en: "today", ko: "ì˜¤ëŠ˜", pos: "TIME", tags: ["daily"] },
  { en: "tomorrow", ko: "ë‚´ì¼", pos: "TIME", tags: ["daily"] },
  { en: "morning", ko: "ì•„ì¹¨", pos: "TIME", tags: ["daily"] },
  { en: "afternoon", ko: "ì˜¤í›„", pos: "TIME", tags: ["daily"] },
  { en: "evening", ko: "ì €ë…", pos: "TIME", tags: ["daily"] },
  { en: "weekend", ko: "ì£¼ë§", pos: "TIME", tags: ["daily"] },
];

export const useLexiconStore = create<LexiconState>()(
  persist(
    (set, get) => ({
      hydrated: false,
      words: [],
      loadedPacks: [],
      isInitialized: false,
      userAddedCoreWords: new Set<string>(),
      isLoadingPacks: false,

      addWord: (w) => {
        const normalizedEn = w.en.toLowerCase().trim();
        const exists = get().words.find(
          (x) => x.pos === w.pos && x.en.toLowerCase().trim() === normalizedEn
        );

        if (exists) {
          console.log(`âš ï¸ ì¤‘ë³µ ë‹¨ì–´ ë¬´ì‹œ: "${w.en}" (${w.pos})`);
          return exists.id;
        }

        const id = `lex_${Date.now()}_${Math.random()
          .toString(36)
          .substr(2, 9)}`;
        const now = new Date().toISOString();

        const item: Lexeme & { source: Source } = {
          id,
          en: w.en.trim(),
          ko: w.ko.trim(),
          pos: w.pos,
          tags: w.tags ?? [],
          createdAt: now,
          source: w.source ?? "user",
        };

        set((s) => ({ words: [item, ...s.words] }));
        return id;
      },

      updateWord: (id, upd) =>
        set((s) => ({
          words: s.words.map((x) =>
            x.id === id
              ? { ...x, ...upd, updatedAt: new Date().toISOString() }
              : x
          ),
        })),

      removeWord: (id) =>
        set((s) => ({ words: s.words.filter((x) => x.id !== id) })),

      search: (q) => {
        const n = q.toLowerCase().trim();
        return get().words.filter(
          (w) => w.en.toLowerCase().includes(n) || w.ko.includes(q)
        );
      },

      findByPos: (pos, categories) => {
        let filtered = get().words.filter((w) => pos.includes(w.pos));
        if (categories?.length) {
          filtered = filtered.filter((w) =>
            w.tags.some((tag) => categories.includes(tag))
          );
        }
        return filtered;
      },

      // âœ… upsertGlobalWords êµ¬í˜„ (JSON íŒ© ë‹¨ì–´ë“¤ì„ globalë¡œ ì„¤ì •)
      upsertGlobalWords: (lexemes) => {
        const state = get();
        const existingKeys = new Set(
          state.words.map((w) => `${w.en.toLowerCase()}_${w.pos}`)
        );

        const newWords: (Lexeme & { source: Source })[] = lexemes
          .filter(
            (lexeme) =>
              !existingKeys.has(`${lexeme.en.toLowerCase()}_${lexeme.pos}`)
          )
          .map((lexeme, index) => ({
            id: `pack_${Date.now()}_${index}`,
            en: lexeme.en,
            ko: lexeme.ko,
            pos: lexeme.pos,
            tags: lexeme.tags || [],
            createdAt: new Date().toISOString(),
            // âœ… í•µì‹¬ ìˆ˜ì •: JSON íŒ© ë‹¨ì–´ë“¤ë„ globalë¡œ ì„¤ì • (ì•± ì½”ì–´ì— í‘œì‹œë˜ë„ë¡)
            source: "global" as Source,
          }));

        if (newWords.length > 0) {
          set((state) => ({
            words: [...state.words, ...newWords],
          }));
          console.log(`âœ… ${newWords.length}ê°œ ê¸€ë¡œë²Œ ë‹¨ì–´ ì¶”ê°€ë¨`);
        }
      },

      // âœ… JSON íŒ© ë¡œë”© í•¨ìˆ˜
      loadJSONPacks: async () => {
        const state = get();
        if (state.isLoadingPacks) {
          console.log("ğŸ“¦ ì´ë¯¸ íŒ© ë¡œë”© ì¤‘...");
          return;
        }

        set({ isLoadingPacks: true });

        try {
          console.log("ğŸ“¦ JSON íŒ© ë¡œë”© ì‹œì‘...");

          // pack-index.json ë¡œë“œ
          const packIndexResponse = await fetch("/data/packs/pack-index.json");
          if (!packIndexResponse.ok) {
            throw new Error(
              `pack-index.json ë¡œë“œ ì‹¤íŒ¨: ${packIndexResponse.status}`
            );
          }

          const packIndex = await packIndexResponse.json();
          console.log(
            "ğŸ“‹ pack-index ë¡œë“œ ì™„ë£Œ:",
            packIndex.packs?.length || 0,
            "ê°œ íŒ©"
          );

          if (!packIndex.packs || !Array.isArray(packIndex.packs)) {
            console.warn("âš ï¸ pack-index.jsonì— ì˜¬ë°”ë¥¸ packs ë°°ì—´ì´ ì—†ìŠµë‹ˆë‹¤");
            return;
          }

          // ì´ë¯¸ ë¡œë“œëœ íŒ©ë“¤ ì²´í¬
          const currentState = get();
          const packsToLoad = packIndex.packs.filter(
            (pack: any) => !currentState.loadedPacks.includes(pack.packId)
          );

          console.log("ğŸ”„ ë¡œë“œí•  íŒ©ë“¤:", packsToLoad.length, "ê°œ");

          let totalLoaded = 0;
          for (const pack of packsToLoad) {
            try {
              console.log(`ğŸ“¥ ${pack.packId} ë¡œë”© ì¤‘...`);
              const response = await fetch(`/data/packs/${pack.file}`);

              if (!response.ok) {
                console.warn(`âš ï¸ ${pack.file} ë¡œë“œ ì‹¤íŒ¨: ${response.status}`);
                continue;
              }

              const packData = await response.json();

              // lexemesë¥¼ ê¸€ë¡œë²Œ ë‹¨ì–´ë¡œ ì¶”ê°€
              if (
                packData.lexemes &&
                Array.isArray(packData.lexemes) &&
                packData.lexemes.length > 0
              ) {
                get().upsertGlobalWords(packData.lexemes);
                totalLoaded += packData.lexemes.length;

                // ë¡œë“œëœ íŒ© ê¸°ë¡
                set((state) => ({
                  loadedPacks: [...state.loadedPacks, pack.packId],
                }));

                console.log(
                  `âœ… ${pack.packId} ì™„ë£Œ: ${packData.lexemes.length}ê°œ ë‹¨ì–´`
                );
              } else {
                console.warn(`âš ï¸ ${pack.packId}ì— ì˜¬ë°”ë¥¸ lexemesê°€ ì—†ìŠµë‹ˆë‹¤`);
              }

              // ê³¼ë„í•œ ìš”ì²­ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ë”œë ˆì´
              await new Promise((resolve) => setTimeout(resolve, 10));
            } catch (error) {
              console.warn(`âš ï¸ ${pack.packId} íŒ© ë¡œë“œ ì‹¤íŒ¨:`, error);
            }
          }

          console.log(`ğŸ‰ JSON íŒ© ë¡œë”© ì™„ë£Œ! ì´ ${totalLoaded}ê°œ ë‹¨ì–´ ì¶”ê°€ë¨`);
        } catch (error) {
          console.error("âŒ JSON íŒ© ë¡œë”© ì‹¤íŒ¨:", error);
        } finally {
          set({ isLoadingPacks: false });
        }
      },

      // âœ… seedIfEmpty ëŒ€ì²´: ê¸°ë³¸ ë‹¨ì–´ë¡œ ì´ˆê¸°í™”
      initializeWithBasicWords: () => {
        const state = get();
        if (state.isInitialized) return;

        console.log("ğŸ”„ ê¸°ë³¸ ë‹¨ì–´ë¡œ ì´ˆê¸°í™” ì¤‘...");

        const existingKeys = new Set(
          state.words.map((w) => `${w.en.toLowerCase()}_${w.pos}`)
        );

        const newWords = BASIC_WORDS.filter(
          (word) => !existingKeys.has(`${word.en.toLowerCase()}_${word.pos}`)
        ).map((word, index) => ({
          id: `basic_${Date.now()}_${index}`,
          en: word.en,
          ko: word.ko,
          pos: word.pos,
          tags: word.tags,
          createdAt: new Date().toISOString(),
          source: "global" as Source,
        }));

        if (newWords.length > 0) {
          set((state) => ({
            words: [...state.words, ...newWords],
            isInitialized: true,
          }));
          console.log(`âœ… ${newWords.length}ê°œ ê¸°ë³¸ ë‹¨ì–´ ì¶”ê°€ë¨`);
        } else {
          set((state) => ({ ...state, isInitialized: true }));
        }
      },

      // âœ… seedIfEmpty êµ¬í˜„
      seedIfEmpty: () => {
        // ê¸°ë³¸ ë‹¨ì–´ ì´ˆê¸°í™”
        get().initializeWithBasicWords();

        // JSON íŒ©ë“¤ë„ ë¡œë“œ (ë¹„ë™ê¸°)
        get()
          .loadJSONPacks()
          .catch((error) => {
            console.warn("JSON íŒ© ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
          });
      },

      // âœ… ì½”ì–´ ë‹¨ì–´ë¥¼ ë‚´ ë‹¨ì–´ì¥ì— ì¶”ê°€ (ì°¸ì¡° ë°©ì‹)
      addCoreWordToUser: (wordId) => {
        set((state) => ({
          userAddedCoreWords: new Set([...state.userAddedCoreWords, wordId]),
        }));
      },

      // âœ… ì½”ì–´ ë‹¨ì–´ë¥¼ ë‚´ ë‹¨ì–´ì¥ì—ì„œ ì œê±°
      removeCoreWordFromUser: (wordId) => {
        set((state) => {
          const newSet = new Set(state.userAddedCoreWords);
          newSet.delete(wordId);
          return { userAddedCoreWords: newSet };
        });
      },

      // âœ… ê¸°ë³¸ ë‹¨ì–´ ë³´ì¥ (íŒ¨í„´ ìƒì„± ì „ í˜¸ì¶œìš©)
      ensureBasicWordsAvailable: () => {
        const state = get();
        const posCount = state.words.reduce((acc, w) => {
          acc[w.pos] = (acc[w.pos] || 0) + 1;
          return acc;
        }, {} as Record<POS, number>);

        // ìµœì†Œ í•„ìš” ë‹¨ì–´ ì²´í¬
        const minimums = {
          VERB: 3,
          PLACE: 3,
          PERSON: 2,
          ITEM: 3,
          TIME: 2,
        };

        let needsMore = false;
        for (const [pos, min] of Object.entries(minimums)) {
          if ((posCount[pos as POS] || 0) < min) {
            needsMore = true;
            break;
          }
        }

        if (needsMore) {
          console.log("ğŸ“ˆ ê¸°ë³¸ ë‹¨ì–´ ì¶”ê°€ í•„ìš”, ìë™ ì¶”ê°€ ì¤‘...");
          get().initializeWithBasicWords();
        }
      },

      // ìµœì†Œ ë‹¨ì–´ ìˆ˜ ë³´ì¥
      ensureMinimumWords: (count, categories) => {
        const current = categories
          ? get().getWordsByCategory(categories)
          : get().words;
        const totalBefore = current.length;

        if (totalBefore >= count) {
          return { added: 0, totalBefore, totalAfter: totalBefore };
        }

        // ë¨¼ì € ê¸°ë³¸ ë‹¨ì–´ë¡œ ì±„ìš°ê¸° ì‹œë„
        get().initializeWithBasicWords();

        const afterBasic = categories
          ? get().getWordsByCategory(categories).length
          : get().words.length;

        return {
          added: afterBasic - totalBefore,
          totalBefore,
          totalAfter: afterBasic,
        };
      },

      getWordsByCategory: (categories) => {
        return get().words.filter((w) =>
          w.tags.some((tag) => categories.includes(tag))
        );
      },

      exportUserWords: () => get().words.filter((w) => w.source === "user"),
    }),
    {
      name: "mypattern-lexicon",
      storage: createJSONStorage(() => localStorage),
      partialize: (s) => ({
        words: s.words.filter((w) => w.source === "user"), // ì‚¬ìš©ì ë‹¨ì–´ë§Œ ì €ì¥
        loadedPacks: s.loadedPacks,
        // isInitializedë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŒ (ë§¤ë²ˆ ì½”ì–´ ë‹¨ì–´ ì²´í¬í•˜ë„ë¡)
        userAddedCoreWords: Array.from(s.userAddedCoreWords),
      }),
      onRehydrateStorage: () => (state, err) => {
        if (!err && state) {
          console.log("[lexiconStore] í•˜ì´ë“œë ˆì´ì…˜ ì™„ë£Œ", {
            words: state.words?.length,
            loadedPacks: state.loadedPacks?.length,
          });

          // âœ… í•˜ì´ë“œë ˆì´ì…˜ ì‹œ Setìœ¼ë¡œ ë³µì›
          if (Array.isArray(state.userAddedCoreWords)) {
            (state as any).userAddedCoreWords = new Set(
              state.userAddedCoreWords
            );
          } else {
            (state as any).userAddedCoreWords = new Set<string>();
          }

          // âœ… ë§¤ë²ˆ ê¸°ë³¸ ë‹¨ì–´ ì´ˆê¸°í™” (isInitializedë¥¼ ì €ì¥í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ)
          setTimeout(() => {
            (state as LexiconState).initializeWithBasicWords();
          }, 100);
        }
        return { hydrated: true };
      },
    }
  )
);
